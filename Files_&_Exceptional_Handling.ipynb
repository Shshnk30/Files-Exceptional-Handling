{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Answer-1**\n",
        "\n",
        "Multithreading (Best for I/O-bound tasks)\n",
        "Use when tasks involve waiting (like reading files, web requests, or database operations).\n",
        "\n",
        "Example: Web scraping, where each thread can handle a request while others wait for responses.\n",
        "\n",
        "Advantage: Threads share memory, so they’re lightweight and ideal for tasks where waiting is more common than computing.\n",
        "\n",
        "Multiprocessing (Best for CPU-bound tasks)\n",
        "Use for heavy computations (like data processing, simulations, or calculations).\n",
        "\n",
        "Example: Processing images in parallel or running multiple simulations.\n",
        "Advantage: Each process runs independently, so multiple cores can work in parallel, making it faster for tasks that require a lot of computing."
      ],
      "metadata": {
        "id": "3nkR0Xtrgncm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer-2**\n",
        "\n",
        "A process pool is a collection of worker processes managed by a pool object in Python’s `multiprocessing` module (or similar libraries in other programming languages). It provides a way to manage and distribute tasks across multiple processes more efficiently.\n",
        "\n",
        "How It Works\n",
        "\n",
        "Instead of creating and managing processes one by one, you create a pool with a fixed number of worker processes. The pool then:\n",
        "\n",
        "1. Distributes tasks among these workers.\n",
        "\n",
        "2. Reuses processes from the pool once they’re done with a task, avoiding the overhead of creating and destroying processes repeatedly.\n",
        "\n",
        "\n",
        "Why It’s Efficient\n",
        "\n",
        "1. Resource Management: You specify the number of processes, so the pool doesn’t overload the system by creating too many processes.\n",
        "\n",
        "2. Reduced Overhead: By reusing the same processes for multiple tasks, a process pool avoids the time and memory cost of constantly starting and ending new processes.\n",
        "\n",
        "3. Simplified Task Distribution: The pool automatically assigns tasks to available workers, allowing you to handle many tasks in parallel with minimal setup.\n",
        "\n",
        "Example Use Case\n",
        "\n",
        "If you need to apply a function to a large list of data (e.g., processing each item), a process pool can efficiently distribute each item to a different process, improving speed without overwhelming system resources.\n",
        "\n",
        "Key Functions\n",
        "\n",
        "Pool.map(): Applies a function to each item in a list, distributing the work across the pool.\n",
        "\n",
        "Pool.apply_async(): Allows asynchronous execution, where you don’t have to wait for each task to complete before starting another.\n",
        "\n",
        "In short, a process pool helps manage multiple processes by reusing a set number of workers, improving speed, and reducing the complexity of handling parallel tasks."
      ],
      "metadata": {
        "id": "SNecQKqBg6BN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer-3**\n",
        "\n",
        "**Multiprocessing** is a programming technique that allows a program to use multiple CPU cores by creating separate processes that run concurrently. In Python, the **multiprocessing** module provides tools to create and manage these processes, enabling tasks to run in parallel.\n",
        "\n",
        "**Why Use Multiprocessing?**\n",
        "\n",
        "Python has a **Global Interpreter Lock (GIL)** that limits true parallelism in a single Python process by allowing only one thread to execute Python bytecode at a time. This can be a bottleneck for CPU-intensive tasks (e.g., heavy computations, data processing) if using threads alone.\n",
        "\n",
        "**Multiprocessing** overcomes this limitation because each process created by the multiprocessing module has its own Python interpreter and memory space. This means:\n",
        "\n",
        "1. **True Parallel Execution**: Multiple processes can run simultaneously on different CPU cores.\n",
        "\n",
        "2. **Better Performance for CPU-Bound Tasks**: For tasks that require a lot of computation, multiprocessing allows you to divide the workload across multiple cores, reducing overall execution time.\n",
        "\n",
        "**When to Use Multiprocessing in Python**\n",
        "\n",
        "- **CPU-Intensive Tasks**: Ideal for tasks like large computations, image or video processing, and scientific simulations.\n",
        "\n",
        "- **Tasks Needing Parallel Processing**: Tasks that can be divided into independent parts that run separately benefit greatly from multiprocessing.\n",
        "\n",
        "**Example Use Case**\n",
        "\n",
        "If you need to perform complex calculations on a large dataset, you can divide the data among multiple processes. Each process works on a subset of the data independently, speeding up the total processing time.\n",
        "\n",
        "In summary, **multiprocessing** is used in Python to achieve parallelism and overcome GIL limitations, making it a powerful tool for optimizing CPU-bound tasks."
      ],
      "metadata": {
        "id": "8AooGrKCh3Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer-4\n",
        "\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list and lock\n",
        "shared_list = []\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Thread function to add numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(10):\n",
        "        num = random.randint(1, 100)\n",
        "\n",
        "        # Acquiring lock to avoid race condition\n",
        "        with list_lock:\n",
        "            shared_list.append(num)\n",
        "            print(f\"Added {num} to list. Current list: {shared_list}\")\n",
        "\n",
        "        time.sleep(random.uniform(0.1, 0.5))\n",
        "\n",
        "# Thread function to remove numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(10):\n",
        "        # Acquiring lock to avoid race condition\n",
        "        with list_lock:\n",
        "            if shared_list:\n",
        "                removed_num = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_num} from list. Current list: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "        time.sleep(random.uniform(0.1, 0.5))\n",
        "\n",
        "# Creating threads\n",
        "adder_thread = threading.Thread(target=add_to_list)\n",
        "remover_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Starting threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Waiting for both threads to complete\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOoombPMiU91",
        "outputId": "081857b2-35d5-4732-c520-d65c532915ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 92 to list. Current list: [92]\n",
            "Removed 92 from list. Current list: []\n",
            "List is empty, nothing to remove.\n",
            "Added 26 to list. Current list: [26]\n",
            "Removed 26 from list. Current list: []\n",
            "Added 13 to list. Current list: [13]\n",
            "Removed 13 from list. Current list: []\n",
            "List is empty, nothing to remove.\n",
            "Added 79 to list. Current list: [79]\n",
            "Added 76 to list. Current list: [79, 76]\n",
            "Removed 79 from list. Current list: [76]\n",
            "Added 13 to list. Current list: [76, 13]\n",
            "Removed 76 from list. Current list: [13]\n",
            "Removed 13 from list. Current list: []\n",
            "Added 64 to list. Current list: [64]\n",
            "Removed 64 from list. Current list: []\n",
            "List is empty, nothing to remove.\n",
            "Added 23 to list. Current list: [23]\n",
            "Added 100 to list. Current list: [23, 100]\n",
            "Added 46 to list. Current list: [23, 100, 46]\n",
            "Final list: [23, 100, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer-5**\n",
        "\n",
        "In Python, to safely share data between **threads** and **processes**, we use these key tools:\n",
        "\n",
        "For Threads (`threading` module):\n",
        "\n",
        "1. **Lock**: Prevents multiple threads from modifying data at the same time.\n",
        "\n",
        "2. **RLock**: Allows a single thread to acquire the lock multiple times.\n",
        "\n",
        "3. **Condition**: Allows threads to wait until certain conditions are met.\n",
        "\n",
        "4. **Semaphore**: Limits the number of threads accessing a resource.\n",
        "\n",
        "5. **Queue**: A thread-safe data structure for passing data between threads.\n",
        "\n",
        "**For Processes (`multiprocessing` module)**:\n",
        "\n",
        "1. **Queue**: Enables safe communication between processes.\n",
        "\n",
        "2. **Pipe**: Provides a simple two-way communication channel between two processes.\n",
        "\n",
        "3. **Value and Array**: Shared memory objects for single values or arrays.\n",
        "\n",
        "4. **Manager**: Allows sharing complex data types (like lists, dicts) across processes.\n",
        "\n",
        "5. **Lock and Semaphore**: Similar to threading tools, but used across multiple processes.\n",
        "\n",
        "These tools help prevent **race conditions** and ensure **safe data sharing**."
      ],
      "metadata": {
        "id": "em_sw90Ti3fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer-6**\n",
        "\n",
        "Exception Handling is Crucial in Concurrent Programs:\n",
        "\n",
        "Stability: An unhandled exception in one thread or process can cause the entire application to crash.\n",
        "\n",
        "Data Integrity: Concurrent tasks often share resources. If one fails unexpectedly, it might leave data in an inconsistent state.\n",
        "\n",
        "Debugging: Exceptions in threads/processes are often harder to detect. Without proper handling, debugging becomes difficult.\n",
        "\n",
        "Resource Management: Exceptions can lead to open files, network connections, or other resources not being released properly, causing memory leaks or deadlocks.\n",
        "\n",
        "Techniques for Handling Exceptions in Concurrent Programs:\n",
        "\n",
        "Try-Except Blocks:\n",
        "\n",
        "Wrap the code in threads or processes with try-except blocks to catch and log exceptions, ensuring they don’t crash the application.\n",
        "Thread/Process Join with Timeout:\n",
        "\n",
        "Use join() with a timeout to detect if a thread or process has hung due to an exception, then handle it gracefully.\n",
        "Using Futures with Executors (in concurrent.futures):\n",
        "\n",
        "Use ThreadPoolExecutor or ProcessPoolExecutor with futures to handle exceptions. Call future.result() which will raise the exception if one occurred, allowing for centralized exception handling.\n",
        "Exception Propagation:\n",
        "\n",
        "Capture exceptions within threads or processes and store them in a shared data structure (like a Queue). The main thread can then handle and log these exceptions.\n",
        "Custom Error Handling Functions:\n",
        "\n",
        "For complex applications, create a custom error handler that logs exceptions and cleans up resources in case of a failure."
      ],
      "metadata": {
        "id": "M-GrQ0sbjX6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer-7\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def calculate_factorial(n):\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Factorial of {n} is {result}\")\n",
        "    return result\n",
        "\n",
        "# List of numbers from 1 to 10\n",
        "numbers = range(1, 11)\n",
        "\n",
        "# Using ThreadPoolExecutor to manage threads\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submitting tasks to the thread pool\n",
        "    futures = [executor.submit(calculate_factorial, num) for num in numbers]\n",
        "\n",
        "    # Collecting results as tasks complete\n",
        "    for future in as_completed(futures):\n",
        "        # This will print the result of each completed task\n",
        "        result = future.result()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIJJ_w-Ojlnw",
        "outputId": "f7fcf454-2987-4bf1-8164-3239e55c6336"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2Factorial of 3 is 6\n",
            "\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer-8\n",
        "\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# List of numbers to compute squares for\n",
        "numbers = range(1, 11)\n",
        "\n",
        "# Function to measure computation time for a given pool size\n",
        "def measure_time(pool_size):\n",
        "    start_time = time.time()\n",
        "\n",
        "    with Pool(pool_size) as pool:\n",
        "        results = pool.map(compute_square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Pool size: {pool_size}, Results: {results}, Time taken: {duration:.4f} seconds\")\n",
        "\n",
        "# Measure time for different pool sizes\n",
        "for size in [2, 4, 8]:\n",
        "    measure_time(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AoqN42UkBtR",
        "outputId": "4aa5a324-55e4-42ec-e1b9-ef8270e47f8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0321 seconds\n",
            "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0486 seconds\n",
            "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0935 seconds\n"
          ]
        }
      ]
    }
  ]
}